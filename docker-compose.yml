services:
  # Infrastructure Services
  postgres:
    image: postgres:16-alpine
    container_name: opsconductor-postgres
    environment:
      POSTGRES_DB: opsconductor
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/complete-schema.sql:/docker-entrypoint-initdb.d/complete-schema.sql
    ports:
      - "5432:5432"
    networks:
      - opsconductor-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: opsconductor-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - opsconductor-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    command: redis-server --appendonly yes

  # API Gateway
  api-gateway:
    build: ./api-gateway
    container_name: opsconductor-gateway
    ports:
      - "3000:3000"
    environment:
      REDIS_URL: redis://redis:6379/0
      IDENTITY_SERVICE_URL: http://identity-service:3001
      ASSET_SERVICE_URL: http://asset-service:3002
      AUTOMATION_SERVICE_URL: http://automation-service:3003
      COMMUNICATION_SERVICE_URL: http://communication-service:3004
      AI_SERVICE_URL: http://ai-command-service:3005
      AI_OVERVIEW_SERVICE_URL: http://ai-overview-service:3000
      NLP_SERVICE_URL: http://nlp-service:3000
      VECTOR_SERVICE_URL: http://vector-service:3000
      LLM_SERVICE_URL: http://llm-service:3000
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_DB: opsconductor
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./api-gateway/main.py:/app/main.py
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Core Services
  identity-service:
    build: ./identity-service
    container_name: opsconductor-identity
    ports:
      - "3001:3001"
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: identity
      REDIS_URL: redis://redis:6379/1
      JWT_SECRET_KEY: your-secret-key-here
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./identity-service/main.py:/app/main.py
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  asset-service:
    build: ./asset-service
    container_name: opsconductor-assets
    ports:
      - "3002:3002"
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: assets
      REDIS_URL: redis://redis:6379/2
      IDENTITY_SERVICE_URL: http://identity-service:3001
      AUTOMATION_SERVICE_URL: http://automation-service:3003
      ENCRYPTION_KEY: Uup6urR_7deaT0yKl9fI5qhohKmPRjvSQt_MCGXSLQw=
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      identity-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./asset-service/main.py:/app/main.py
      - ./asset-service/main_with_groups.py:/app/main_with_groups.py
      - ./asset-service/data:/app/data
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  automation-service:
    build: ./automation-service
    container_name: opsconductor-automation
    ports:
      - "3003:3003"
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: automation
      REDIS_URL: redis://redis:6379/3
      IDENTITY_SERVICE_URL: http://identity-service:3001
      ASSET_SERVICE_URL: http://asset-service:3002
      COMMUNICATION_SERVICE_URL: http://communication-service:3004
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      identity-service:
        condition: service_healthy
      asset-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./automation-service/main.py:/app/main.py
      - ./automation-service/worker.py:/app/worker.py
      - ./automation-service/celery_monitor.py:/app/celery_monitor.py
      - ./automation-service/websocket_manager.py:/app/websocket_manager.py
      - ./automation-service/libraries:/app/libraries
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  communication-service:
    build: ./communication-service
    container_name: opsconductor-communication
    ports:
      - "3004:3004"
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: communication
      REDIS_URL: redis://redis:6379/4
      IDENTITY_SERVICE_URL: http://identity-service:3001
      SMTP_HOST: smtp.gmail.com
      SMTP_PORT: 587
      SMTP_USERNAME: your-email@gmail.com
      SMTP_PASSWORD: your-app-password
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      identity-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./communication-service/main.py:/app/main.py
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Vector Database for AI Knowledge
  chromadb:
    image: chromadb/chroma:0.5.0
    container_name: opsconductor-chromadb
    ports:
      - "8000:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    networks:
      - opsconductor-net
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_AUTH_PROVIDER=
      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=
      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=
      - ANONYMIZED_TELEMETRY=False
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # AI Microservices
  nlp-service:
    build: ./nlp-service
    container_name: opsconductor-nlp
    ports:
      - "3006:3000"
    environment:
      REDIS_URL: redis://redis:6379/6
      CUDA_VISIBLE_DEVICES: all
      NVIDIA_VISIBLE_DEVICES: all
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./nlp-service/main.py:/app/main.py
      - ./nlp-service/nlp_processor.py:/app/nlp_processor.py
      - ./shared:/app/shared
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  vector-service:
    build: ./vector-service
    container_name: opsconductor-vector
    ports:
      - "3007:3000"
    environment:
      REDIS_URL: redis://redis:6379/7
      CHROMADB_URL: http://chromadb:8000
      CUDA_VISIBLE_DEVICES: all
      NVIDIA_VISIBLE_DEVICES: all
    depends_on:
      redis:
        condition: service_healthy
      chromadb:
        condition: service_started
    networks:
      - opsconductor-net
    volumes:
      - ./vector-service/main.py:/app/main.py
      - ./vector-service/vector_store.py:/app/vector_store.py
      - ./shared:/app/shared
      - vector_data:/app/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  llm-service:
    build: ./llm-service
    container_name: opsconductor-llm
    ports:
      - "3008:3000"
    environment:
      REDIS_URL: redis://redis:6379/8
      OLLAMA_HOST: http://ollama:11434
      DEFAULT_LLM_MODEL: llama2:latest
      CUDA_VISIBLE_DEVICES: all
      NVIDIA_VISIBLE_DEVICES: all
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - opsconductor-net
    volumes:
      - ./llm-service/main.py:/app/main.py
      - ./llm-service/llm_engine.py:/app/llm_engine.py
      - ./shared:/app/shared
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  ai-overview-service:
    build: ./ai-orchestrator
    container_name: opsconductor-ai-overview
    ports:
      - "3010:3000"
    environment:
      NLP_SERVICE_URL: http://nlp-service:3000
      VECTOR_SERVICE_URL: http://vector-service:3000
      LLM_SERVICE_URL: http://llm-service:3000
      ASSET_SERVICE_URL: http://asset-service:3002
      AUTOMATION_SERVICE_URL: http://automation-service:3003
      REDIS_URL: redis://redis:6379/5
    depends_on:
      redis:
        condition: service_healthy
      nlp-service:
        condition: service_healthy
      vector-service:
        condition: service_healthy
      llm-service:
        condition: service_healthy
      asset-service:
        condition: service_healthy
      automation-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./ai-orchestrator/main.py:/app/main.py
      - ./ai-orchestrator/orchestrator.py:/app/orchestrator.py
      - ./ai-orchestrator/protocol_manager.py:/app/protocol_manager.py
      - ./ai-orchestrator/workflow_generator.py:/app/workflow_generator.py
      - ./ai-orchestrator/knowledge_manager.py:/app/knowledge_manager.py
      - ./shared:/app/shared
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Ollama LLM Server
  ollama:
    image: ollama/ollama:latest
    container_name: opsconductor-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    networks:
      - opsconductor-net
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # AI Command Service - Core Intent Classification and Command Execution
  ai-command-service:
    build: ./ai-service
    container_name: opsconductor-ai-command
    ports:
      - "3005:3005"
    environment:
      ASSET_SERVICE_URL: http://asset-service:3002
      AUTOMATION_SERVICE_URL: http://automation-service:3003
      REDIS_URL: redis://redis:6379/9
      CHROMADB_URL: http://chromadb:8000
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      OLLAMA_HOST: http://ollama:11434
    depends_on:
      redis:
        condition: service_healthy
      asset-service:
        condition: service_healthy
      automation-service:
        condition: service_healthy
      chromadb:
        condition: service_started
      ollama:
        condition: service_started
    networks:
      - opsconductor-net
    volumes:
      # Core AI Service Files - TRACKED FOR EXCEPTIONS & DEBUGGING
      - ./ai-service/main.py:/app/main.py                                    # Main FastAPI app entry point
      - ./ai-service/ai_engine.py:/app/ai_engine.py                          # Modular AI orchestrator (601 lines)
      
      # Service Clients - TRACKED FOR EXTERNAL API FAILURES  
      - ./ai-service/asset_client.py:/app/asset_client.py                     # Asset service integration
      - ./ai-service/automation_client.py:/app/automation_client.py           # Automation service integration
      - ./ai-service/communication_client.py:/app/communication_client.py     # Communication service integration
      
      # Core AI Components - TRACKED FOR ML/NLP FAILURES
      - ./ai-service/nlp_processor.py:/app/nlp_processor.py                   # Natural language processing
      - ./ai-service/vector_store.py:/app/vector_store.py                     # Vector embeddings storage
      - ./ai-service/learning_engine.py:/app/learning_engine.py               # Machine learning engine
      - ./ai-service/predictive_analytics.py:/app/predictive_analytics.py     # Predictive analytics
      - ./ai-service/learning_api.py:/app/learning_api.py                     # Learning API endpoints
      
      # Infrastructure Components - TRACKED FOR CONNECTIVITY ISSUES
      - ./ai-service/protocol_manager.py:/app/protocol_manager.py             # Protocol management
      - ./ai-service/workflow_generator.py:/app/workflow_generator.py         # Workflow generation
      - ./ai-service/schema_introspector.py:/app/schema_introspector.py       # Database schema analysis
      
      # Modular Query Handlers - TRACKED FOR INTENT CLASSIFICATION FAILURES
      - ./ai-service/query_handlers/__init__.py:/app/query_handlers/__init__.py
      - ./ai-service/query_handlers/base_handler.py:/app/query_handlers/base_handler.py
      - ./ai-service/query_handlers/automation_queries.py:/app/query_handlers/automation_queries.py
      - ./ai-service/query_handlers/infrastructure_queries.py:/app/query_handlers/infrastructure_queries.py
      - ./ai-service/query_handlers/communication_queries.py:/app/query_handlers/communication_queries.py
      - ./ai-service/query_handlers/dynamic_schema_queries.py:/app/query_handlers/dynamic_schema_queries.py
      
      # Test Files - TRACKED FOR DEVELOPMENT DEBUGGING
      - ./ai-service/test_phase3_learning.py:/app/test_phase3_learning.py     # Learning system tests
      - ./ai-service/test_tag_functionality.py:/app/test_tag_functionality.py # Tag functionality tests
      
      # Shared Libraries - TRACKED FOR CROSS-SERVICE ISSUES
      - ./shared:/app/shared                                                  # Shared utilities and middleware
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Background Workers
  automation-worker-1:
    build: ./automation-service
    container_name: opsconductor-worker-1
    command: celery -A worker worker --loglevel=info --concurrency=12 --hostname=worker-1@%h
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: automation
      REDIS_URL: redis://redis:6379/3
      IDENTITY_SERVICE_URL: http://identity-service:3001
      ASSET_SERVICE_URL: http://asset-service:3002
      COMMUNICATION_SERVICE_URL: http://communication-service:3004
      HTTP_PROXY: http://nginx:8080
      HTTPS_PROXY: http://nginx:8080
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      automation-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./automation-service/main.py:/app/main.py
      - ./automation-service/worker.py:/app/worker.py
      - ./automation-service/celery_monitor.py:/app/celery_monitor.py
      - ./automation-service/websocket_manager.py:/app/websocket_manager.py
      - ./automation-service/libraries:/app/libraries
      - ./shared:/app/shared
    restart: unless-stopped

  automation-worker-2:
    build: ./automation-service
    container_name: opsconductor-worker-2
    command: celery -A worker worker --loglevel=info --concurrency=12 --hostname=worker-2@%h
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_SCHEMA: automation
      REDIS_URL: redis://redis:6379/3
      IDENTITY_SERVICE_URL: http://identity-service:3001
      ASSET_SERVICE_URL: http://asset-service:3002
      COMMUNICATION_SERVICE_URL: http://communication-service:3004
      HTTP_PROXY: http://nginx:8080
      HTTPS_PROXY: http://nginx:8080
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      automation-service:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./automation-service/main.py:/app/main.py
      - ./automation-service/worker.py:/app/worker.py
      - ./automation-service/celery_monitor.py:/app/celery_monitor.py
      - ./automation-service/websocket_manager.py:/app/websocket_manager.py
      - ./automation-service/libraries:/app/libraries
      - ./shared:/app/shared
    restart: unless-stopped

  automation-scheduler:
    build: ./automation-service
    container_name: opsconductor-scheduler
    command: celery -A worker beat --loglevel=info
    environment:
      REDIS_URL: redis://redis:6379/3
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - scheduler_data:/app/data
    restart: unless-stopped

  # Celery Monitoring with Flower
  celery-monitor:
    build: ./automation-service
    container_name: opsconductor-celery-monitor
    command: celery -A worker flower --port=5555 --broker=redis://redis:6379/3
    ports:
      - "5555:5555"
    environment:
      REDIS_URL: redis://redis:6379/3
      FLOWER_BASIC_AUTH: admin:admin123
    depends_on:
      redis:
        condition: service_healthy
      automation-worker-1:
        condition: service_started
      automation-worker-2:
        condition: service_started
    networks:
      - opsconductor-net
    volumes:
      - ./automation-service/main.py:/app/main.py
      - ./automation-service/worker.py:/app/worker.py
      - ./automation-service/celery_monitor.py:/app/celery_monitor.py
      - ./automation-service/websocket_manager.py:/app/websocket_manager.py
      - ./automation-service/libraries:/app/libraries
      - ./shared:/app/shared
    restart: unless-stopped



  # Frontend
  frontend:
    build: ./frontend
    container_name: opsconductor-frontend
    # Removed REACT_APP_API_URL to use dynamic URL detection
    depends_on:
      api-gateway:
        condition: service_healthy
    networks:
      - opsconductor-net
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
      - ./frontend/package.json:/app/package.json
      - ./frontend/package-lock.json:/app/package-lock.json
      - ./frontend/tsconfig.json:/app/tsconfig.json
      - ./frontend/.env:/app/.env
    restart: unless-stopped

  # Nginx Reverse Proxy
  nginx:
    build: ./nginx
    container_name: opsconductor-nginx
    ports:
      - "80:80"
      - "443:443"
      - "3100:443"  # Additional HTTPS port for compatibility
      - "8080:8080"  # Forward proxy port for outbound connections
    depends_on:
      - api-gateway
      - frontend
    networks:
      - opsconductor-net
    restart: unless-stopped

networks:
  opsconductor-net:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  scheduler_data:
  chromadb_data:
  ollama_models:
  vector_data: