"""
OpsConductor AI Engine - Complete Integration
One clean, seamless AI system with full protocol support and vector intelligence
"""
import asyncio
import logging
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
import spacy
import ollama
import asyncpg
import redis.asyncio as redis
from vector_store import OpsConductorVectorStore
from protocol_manager import protocol_manager, ProtocolResult
from learning_engine import learning_engine, PredictionResult

logger = logging.getLogger(__name__)

class OpsConductorAI:
    """Complete AI Engine for OpsConductor with Protocol Integration"""
    
    def __init__(self):
        self.nlp = None
        self.ollama_client = ollama.AsyncClient()
        self.vector_store = None
        self.db_pool = None
        self.redis_client = None
        self.protocol_manager = protocol_manager
        self.learning_engine = learning_engine
        self.system_knowledge = {}
        
    async def initialize(self):
        """Initialize all AI components"""
        try:
            # Initialize spaCy
            self.nlp = spacy.load("en_core_web_sm")
            logger.info("SpaCy model loaded successfully")
            
            # Initialize vector store
            import chromadb
            chroma_client = chromadb.Client()
            self.vector_store = OpsConductorVectorStore(chroma_client)
            await self.vector_store.initialize_collections()
            logger.info("Vector store initialized")
            
            # Initialize database connection
            self.db_pool = await asyncpg.create_pool(
                host="postgres",
                port=5432,
                user="postgres",
                password="postgres123",
                database="opsconductor",
                min_size=2,
                max_size=10
            )
            logger.info("Database pool created")
            
            # Initialize Redis connection
            self.redis_client = redis.Redis(
                host="redis",
                port=6379,
                decode_responses=True
            )
            logger.info("Redis client initialized")
            
            # Load system knowledge
            await self.load_system_knowledge()
            
            logger.info("Complete AI Engine initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize AI Engine: {e}")
            return False
    
    async def load_system_knowledge(self):
        """Load system knowledge from database"""
        try:
            async with self.db_pool.acquire() as conn:
                # Load target information
                targets = await conn.fetch("SELECT * FROM assets.targets LIMIT 100")
                self.system_knowledge['targets'] = [dict(t) for t in targets]
                
                # Load enhanced targets
                enhanced_targets = await conn.fetch("SELECT * FROM assets.enhanced_targets LIMIT 100")
                self.system_knowledge['enhanced_targets'] = [dict(t) for t in enhanced_targets]
                
                # Load automation jobs
                jobs = await conn.fetch("SELECT * FROM automation.jobs ORDER BY created_at DESC LIMIT 50")
                self.system_knowledge['recent_jobs'] = [dict(j) for j in jobs]
                
                logger.info(f"Loaded system knowledge: {len(targets)} targets, {len(enhanced_targets)} enhanced targets, {len(jobs)} recent jobs")
                
        except Exception as e:
            logger.error(f"Failed to load system knowledge: {e}")
    
    async def get_relevant_context(self, query: str, limit: int = 3) -> List[Dict]:
        """Get relevant context from vector store"""
        try:
            if self.vector_store:
                return await self.vector_store.search_knowledge(query, limit=limit)
            return []
        except Exception as e:
            logger.error(f"Failed to get relevant context: {e}")
            return []
    
    async def detect_intent(self, message: str) -> Dict[str, Any]:
        """Enhanced intent detection with protocol awareness"""
        message_lower = message.lower()
        
        # Protocol-specific intents
        if any(word in message_lower for word in ['snmp', 'network', 'switch', 'router', 'monitor']):
            return {
                "intent": "network_monitoring",
                "confidence": 0.9,
                "protocols": ["snmp"],
                "action": "monitor_network_devices"
            }
        
        if any(word in message_lower for word in ['email', 'alert', 'notify', 'send mail']):
            return {
                "intent": "email_notification",
                "confidence": 0.9,
                "protocols": ["smtp"],
                "action": "send_notification"
            }
        
        if any(word in message_lower for word in ['ssh', 'remote', 'execute', 'run command']):
            return {
                "intent": "remote_execution",
                "confidence": 0.9,
                "protocols": ["ssh"],
                "action": "execute_remote_command"
            }
        
        if any(word in message_lower for word in ['camera', 'vapix', 'axis', 'motion']):
            return {
                "intent": "camera_management",
                "confidence": 0.9,
                "protocols": ["vapix"],
                "action": "manage_cameras"
            }
        
        # System query intents
        if any(word in message_lower for word in ['target groups', 'groups', 'target group']):
            return {
                "intent": "target_group_query",
                "confidence": 0.9,
                "action": "query_target_groups"
            }
        
        if any(word in message_lower for word in ['targets', 'servers', 'hosts', 'machines']):
            return {
                "intent": "system_query",
                "confidence": 0.8,
                "action": "query_targets"
            }
        
        if any(word in message_lower for word in ['workflows', 'workflow', 'templates']):
            return {
                "intent": "workflow_query", 
                "confidence": 0.9,
                "action": "query_workflows"
            }
        
        if any(word in message_lower for word in ['executions', 'execution history', 'job history', 'runs']):
            return {
                "intent": "execution_history_query",
                "confidence": 0.9, 
                "action": "query_execution_history"
            }
        
        if any(word in message_lower for word in ['jobs', 'automation', 'tasks']):
            return {
                "intent": "automation_query",
                "confidence": 0.8,
                "action": "query_jobs"
            }
        
        # Script generation intents
        if any(word in message_lower for word in ['script', 'powershell', 'bash', 'create', 'generate']):
            return {
                "intent": "script_generation",
                "confidence": 0.8,
                "action": "generate_script"
            }
        
        # Recommendations intents
        if any(word in message_lower for word in ['recommend', 'suggest', 'advice', 'optimize', 'improve']):
            return {
                "intent": "recommendations",
                "confidence": 0.8,
                "action": "get_recommendations"
            }
        
        # Performance and analytics intents
        if any(word in message_lower for word in ['performance', 'metrics', 'statistics', 'stats', 'trends']):
            return {
                "intent": "performance_query",
                "confidence": 0.9,
                "action": "query_performance"
            }
        
        if any(word in message_lower for word in ['errors', 'failures', 'error analysis', 'failure analysis']):
            return {
                "intent": "error_analysis_query",
                "confidence": 0.9,
                "action": "query_error_analysis"
            }
        
        if any(word in message_lower for word in ['notifications', 'alerts sent', 'email history', 'messages']):
            return {
                "intent": "notification_history_query",
                "confidence": 0.9,
                "action": "query_notification_history"
            }
        
        # System health intents
        if any(word in message_lower for word in ['health', 'status', 'anomaly', 'alert']):
            return {
                "intent": "system_health",
                "confidence": 0.8,
                "action": "system_health"
            }
        
        # Greeting intents
        if any(word in message_lower for word in ['hello', 'hi', 'hey', 'help']):
            return {
                "intent": "greeting",
                "confidence": 0.7,
                "action": "provide_greeting"
            }
        
        # Default to general query
        return {
            "intent": "general_query",
            "confidence": 0.5,
            "action": "general_response"
        }
    
    async def process_message(self, message: str, user_id: str = "system") -> Dict[str, Any]:
        """Process user message with complete protocol integration and learning"""
        start_time = datetime.utcnow()
        
        try:
            # Detect intent
            intent_result = await self.detect_intent(message)
            
            # Get relevant context
            context = await self.get_relevant_context(message)
            
            # Store interaction for learning
            if self.vector_store:
                await self.vector_store.store_interaction(user_id, message, intent_result)
            
            # Get failure risk prediction for operations
            prediction = None
            if intent_result["action"] in ["network_monitoring", "execute_remote_command", "manage_cameras"]:
                target_info = {"operation": intent_result["action"], "user_id": user_id}
                prediction = await self.learning_engine.predict_failure_risk(
                    intent_result["action"], target_info, user_id
                )
            
            # Route to appropriate handler
            response = None
            if intent_result["action"] == "network_monitoring":
                response = await self.handle_network_monitoring(message, context, prediction)
            elif intent_result["action"] == "send_notification":
                response = await self.handle_email_notification(message, context, prediction)
            elif intent_result["action"] == "execute_remote_command":
                response = await self.handle_remote_execution(message, context, prediction)
            elif intent_result["action"] == "manage_cameras":
                response = await self.handle_camera_management(message, context, prediction)
            elif intent_result["action"] == "query_targets":
                response = await self.handle_target_query(message, context)
            elif intent_result["action"] == "query_target_groups":
                response = await self.handle_target_group_query(message, context)
            elif intent_result["action"] == "query_jobs":
                response = await self.handle_job_query(message, context)
            elif intent_result["action"] == "query_workflows":
                response = await self.handle_workflow_query(message, context)
            elif intent_result["action"] == "query_execution_history":
                response = await self.handle_execution_history_query(message, context)
            elif intent_result["action"] == "query_performance":
                response = await self.handle_performance_query(message, context)
            elif intent_result["action"] == "query_error_analysis":
                response = await self.handle_error_analysis_query(message, context)
            elif intent_result["action"] == "query_notification_history":
                response = await self.handle_notification_history_query(message, context)
            elif intent_result["action"] == "generate_script":
                response = await self.handle_script_generation(message, context)
            elif intent_result["action"] == "provide_greeting":
                response = await self.handle_greeting(message, context)
            elif intent_result["action"] == "get_recommendations":
                response = await self.handle_user_recommendations(user_id, context)
            elif intent_result["action"] == "system_health":
                response = await self.handle_system_health_query(context)
            else:
                response = await self.handle_general_query(message, context)
            
            # Record execution for learning
            end_time = datetime.utcnow()
            duration = (end_time - start_time).total_seconds()
            success = response.get("success", True)
            
            await self.learning_engine.record_execution(
                user_id=user_id,
                operation_type=intent_result["action"],
                target_info={"message": message, "intent": intent_result},
                duration=duration,
                success=success,
                error_message=response.get("error") if not success else None
            )
            
            # Add prediction info to response if available
            if prediction:
                response["prediction"] = prediction.to_dict()
            
            return response
                
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            
            # Record failed execution
            end_time = datetime.utcnow()
            duration = (end_time - start_time).total_seconds()
            await self.learning_engine.record_execution(
                user_id=user_id,
                operation_type="unknown",
                target_info={"message": message},
                duration=duration,
                success=False,
                error_message=str(e)
            )
            
            return {
                "response": f"I encountered an error processing your request: {str(e)}",
                "intent": "error",
                "success": False
            }
    
    async def handle_network_monitoring(self, message: str, context: List[Dict], prediction: Optional[PredictionResult] = None) -> Dict[str, Any]:
        """Handle SNMP network monitoring requests"""
        try:
            # Find network targets
            network_targets = []
            for target in self.system_knowledge.get('targets', []):
                if any(tag in str(target.get('tags', '')).lower() for tag in ['switch', 'router', 'network']):
                    network_targets.append(target)
            
            if not network_targets:
                return {
                    "response": "ðŸ” No network devices found in your targets. Please add network switches or routers with SNMP tags.",
                    "intent": "network_monitoring",
                    "success": False
                }
            
            # Generate SNMP monitoring response
            response = f"ðŸŒ **Network Monitoring Available**\n\n"
            response += f"**Found {len(network_targets)} network devices:**\n"
            
            for target in network_targets[:5]:  # Show first 5
                response += f"â€¢ {target.get('hostname', 'Unknown')} ({target.get('ip_address', 'No IP')})\n"
            
            if len(network_targets) > 5:
                response += f"â€¢ ... and {len(network_targets) - 5} more devices\n"
            
            response += "\n**Available SNMP Operations:**\n"
            response += "â€¢ `get_system_info` - Device information\n"
            response += "â€¢ `get_interface_stats` - Network interface statistics\n"
            response += "â€¢ `get_cpu_usage` - CPU utilization\n"
            response += "â€¢ `get_memory_usage` - Memory utilization\n"
            response += "â€¢ `walk_oid` - Custom SNMP walks\n"
            
            response += "\nðŸ’¡ **Example:** \"Check system info on switch-01\" or \"Monitor all network interfaces\""
            
            # Add prediction information if available
            if prediction:
                response += f"\n\nðŸ”® **AI Prediction:**\n"
                response += f"â€¢ Risk Level: {prediction.predicted_outcome.title()}\n"
                response += f"â€¢ Confidence: {prediction.confidence:.1%}\n"
                
                if prediction.risk_factors:
                    response += f"â€¢ Risk Factors: {', '.join(prediction.risk_factors[:2])}\n"
                
                if prediction.recommendations:
                    response += f"â€¢ Recommendation: {prediction.recommendations[0]}\n"
            
            return {
                "response": response,
                "intent": "network_monitoring",
                "success": True,
                "data": {
                    "network_targets": len(network_targets),
                    "protocols": ["snmp"],
                    "prediction": prediction.to_dict() if prediction else None
                }
            }
            
        except Exception as e:
            logger.error(f"Network monitoring error: {e}")
            return {
                "response": f"âŒ Error handling network monitoring: {str(e)}",
                "intent": "network_monitoring",
                "success": False
            }
    
    async def handle_email_notification(self, message: str, context: List[Dict], prediction: Optional[PredictionResult] = None) -> Dict[str, Any]:
        """Handle SMTP email notification requests"""
        try:
            response = "ðŸ“§ **Email Notification System**\n\n"
            response += "**Available SMTP Operations:**\n"
            response += "â€¢ `send_email` - Send custom email messages\n"
            response += "â€¢ `send_alert` - Send formatted system alerts\n"
            response += "â€¢ `test_connection` - Test SMTP server connectivity\n"
            
            response += "\n**Supported Alert Types:**\n"
            response += "â€¢ System alerts (critical, warning, info)\n"
            response += "â€¢ Automation job notifications\n"
            response += "â€¢ Custom formatted messages\n"
            
            response += "\nðŸ’¡ **Example:** \"Send alert about disk space\" or \"Email the ops team about server status\""
            
            return {
                "response": response,
                "intent": "email_notification",
                "success": True,
                "data": {
                    "protocols": ["smtp"]
                }
            }
            
        except Exception as e:
            logger.error(f"Email notification error: {e}")
            return {
                "response": f"âŒ Error handling email notification: {str(e)}",
                "intent": "email_notification",
                "success": False
            }
    
    async def handle_remote_execution(self, message: str, context: List[Dict], prediction: Optional[PredictionResult] = None) -> Dict[str, Any]:
        """Handle SSH remote execution requests"""
        try:
            # Find SSH-capable targets
            ssh_targets = []
            for target in self.system_knowledge.get('targets', []):
                if target.get('os_type') in ['linux', 'unix'] or 'ssh' in str(target.get('tags', '')).lower():
                    ssh_targets.append(target)
            
            response = f"ðŸ” **Remote Execution via SSH**\n\n"
            response += f"**Found {len(ssh_targets)} SSH-capable targets**\n\n"
            
            response += "**Available SSH Operations:**\n"
            response += "â€¢ `run_command` - Execute single commands\n"
            response += "â€¢ `run_script` - Execute complete scripts\n"
            response += "â€¢ `file_transfer` - Upload/download files\n"
            
            response += "\n**Supported Script Types:**\n"
            response += "â€¢ Bash scripts (/bin/bash)\n"
            response += "â€¢ Python scripts (/usr/bin/python3)\n"
            response += "â€¢ Custom interpreters\n"
            
            response += "\nðŸ’¡ **Example:** \"Run disk check on all Linux servers\" or \"Execute maintenance script\""
            
            return {
                "response": response,
                "intent": "remote_execution",
                "success": True,
                "data": {
                    "ssh_targets": len(ssh_targets),
                    "protocols": ["ssh"]
                }
            }
            
        except Exception as e:
            logger.error(f"Remote execution error: {e}")
            return {
                "response": f"âŒ Error handling remote execution: {str(e)}",
                "intent": "remote_execution",
                "success": False
            }
    
    async def handle_camera_management(self, message: str, context: List[Dict], prediction: Optional[PredictionResult] = None) -> Dict[str, Any]:
        """Handle VAPIX camera management requests"""
        try:
            # Find camera targets
            camera_targets = []
            for target in self.system_knowledge.get('targets', []):
                if any(tag in str(target.get('tags', '')).lower() for tag in ['camera', 'axis', 'vapix']):
                    camera_targets.append(target)
            
            response = f"ðŸ“¹ **Camera Management via VAPIX**\n\n"
            response += f"**Found {len(camera_targets)} camera devices**\n\n"
            
            response += "**Available VAPIX Operations:**\n"
            response += "â€¢ `get_system_info` - Camera system information\n"
            response += "â€¢ `setup_motion_detection` - Configure motion alerts\n"
            response += "â€¢ `capture_image` - Take snapshots\n"
            response += "â€¢ `get_motion_events` - Retrieve motion events\n"
            
            response += "\n**Motion Detection Features:**\n"
            response += "â€¢ Configurable sensitivity levels\n"
            response += "â€¢ Real-time motion alerts\n"
            response += "â€¢ Event logging and retrieval\n"
            
            response += "\nðŸ’¡ **Example:** \"Setup motion detection on all cameras\" or \"Capture image from camera-01\""
            
            return {
                "response": response,
                "intent": "camera_management",
                "success": True,
                "data": {
                    "camera_targets": len(camera_targets),
                    "protocols": ["vapix"]
                }
            }
            
        except Exception as e:
            logger.error(f"Camera management error: {e}")
            return {
                "response": f"âŒ Error handling camera management: {str(e)}",
                "intent": "camera_management",
                "success": False
            }
    
    async def handle_target_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle target/system queries"""
        try:
            targets = self.system_knowledge.get('targets', [])
            enhanced_targets = self.system_knowledge.get('enhanced_targets', [])
            
            # Parse query for specific filters
            message_lower = message.lower()
            
            if 'win10' in message_lower or 'windows 10' in message_lower:
                filtered_targets = [t for t in targets if 'win10' in str(t.get('tags', '')).lower()]
                filter_desc = "Windows 10"
            elif 'linux' in message_lower:
                filtered_targets = [t for t in targets if t.get('os_type') == 'linux']
                filter_desc = "Linux"
            elif 'online' in message_lower:
                filtered_targets = [t for t in targets if t.get('status') == 'online']
                filter_desc = "Online"
            elif 'offline' in message_lower:
                filtered_targets = [t for t in targets if t.get('status') == 'offline']
                filter_desc = "Offline"
            else:
                filtered_targets = targets
                filter_desc = "All"
            
            response = f"ðŸŽ¯ **{filter_desc} Targets**\n\n"
            response += f"**Found {len(filtered_targets)} targets:**\n\n"
            
            # Group by status
            online_targets = [t for t in filtered_targets if t.get('status') == 'online']
            offline_targets = [t for t in filtered_targets if t.get('status') == 'offline']
            
            if online_targets:
                response += f"**ðŸŸ¢ Online ({len(online_targets)}):**\n"
                for target in online_targets[:10]:  # Show first 10
                    response += f"â€¢ {target.get('hostname', 'Unknown')} ({target.get('ip_address', 'No IP')})\n"
                if len(online_targets) > 10:
                    response += f"â€¢ ... and {len(online_targets) - 10} more\n"
                response += "\n"
            
            if offline_targets:
                response += f"**ðŸ”´ Offline ({len(offline_targets)}):**\n"
                for target in offline_targets[:5]:  # Show first 5
                    response += f"â€¢ {target.get('hostname', 'Unknown')} ({target.get('ip_address', 'No IP')})\n"
                if len(offline_targets) > 5:
                    response += f"â€¢ ... and {len(offline_targets) - 5} more\n"
            
            response += "\nðŸ’¡ **Available Actions:**\n"
            response += "â€¢ Create automation for these targets\n"
            response += "â€¢ Monitor with SNMP (network devices)\n"
            response += "â€¢ Execute commands via SSH (Linux/Unix)\n"
            response += "â€¢ Send notifications about status changes"
            
            return {
                "response": response,
                "intent": "system_query",
                "success": True,
                "data": {
                    "total_targets": len(filtered_targets),
                    "online": len(online_targets),
                    "offline": len(offline_targets),
                    "filter": filter_desc
                }
            }
            
        except Exception as e:
            logger.error(f"Target query error: {e}")
            return {
                "response": f"âŒ Error querying targets: {str(e)}",
                "intent": "system_query",
                "success": False
            }
    
    async def handle_job_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle automation job queries"""
        try:
            jobs = self.system_knowledge.get('recent_jobs', [])
            
            response = f"âš™ï¸ **Recent Automation Jobs**\n\n"
            response += f"**Found {len(jobs)} recent jobs:**\n\n"
            
            # Group by status
            running_jobs = [j for j in jobs if j.get('status') == 'running']
            completed_jobs = [j for j in jobs if j.get('status') == 'completed']
            failed_jobs = [j for j in jobs if j.get('status') == 'failed']
            
            if running_jobs:
                response += f"**ðŸ”„ Running ({len(running_jobs)}):**\n"
                for job in running_jobs[:5]:
                    response += f"â€¢ {job.get('name', 'Unnamed')} - Started {job.get('created_at', 'Unknown')}\n"
                response += "\n"
            
            if completed_jobs:
                response += f"**âœ… Completed ({len(completed_jobs)}):**\n"
                for job in completed_jobs[:5]:
                    response += f"â€¢ {job.get('name', 'Unnamed')} - {job.get('created_at', 'Unknown')}\n"
                response += "\n"
            
            if failed_jobs:
                response += f"**âŒ Failed ({len(failed_jobs)}):**\n"
                for job in failed_jobs[:3]:
                    response += f"â€¢ {job.get('name', 'Unnamed')} - {job.get('created_at', 'Unknown')}\n"
                response += "\n"
            
            response += "ðŸ’¡ **Available Actions:**\n"
            response += "â€¢ Create new automation workflows\n"
            response += "â€¢ Generate scripts for common tasks\n"
            response += "â€¢ Schedule recurring jobs\n"
            response += "â€¢ Monitor job execution status"
            
            return {
                "response": response,
                "intent": "automation_query",
                "success": True,
                "data": {
                    "total_jobs": len(jobs),
                    "running": len(running_jobs),
                    "completed": len(completed_jobs),
                    "failed": len(failed_jobs)
                }
            }
            
        except Exception as e:
            logger.error(f"Job query error: {e}")
            return {
                "response": f"âŒ Error querying jobs: {str(e)}",
                "intent": "automation_query",
                "success": False
            }
    
    async def handle_script_generation(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle script generation requests using Ollama"""
        try:
            # Determine script type from message
            message_lower = message.lower()
            
            if 'powershell' in message_lower:
                script_type = "PowerShell"
                model_prompt = "Generate a PowerShell script"
            elif 'bash' in message_lower:
                script_type = "Bash"
                model_prompt = "Generate a Bash script"
            elif 'python' in message_lower:
                script_type = "Python"
                model_prompt = "Generate a Python script"
            else:
                script_type = "PowerShell"  # Default
                model_prompt = "Generate a PowerShell script"
            
            # Create enhanced prompt with context
            enhanced_prompt = f"""
{model_prompt} for the following request: {message}

Context from OpsConductor system:
- Available targets: {len(self.system_knowledge.get('targets', []))}
- Recent automations: {len(self.system_knowledge.get('recent_jobs', []))}

Requirements:
1. Include proper error handling
2. Add logging/output for monitoring
3. Make it production-ready
4. Include comments explaining the logic
5. Follow best practices for {script_type}

Generate only the script code with comments.
"""
            
            # Generate script using Ollama
            try:
                ollama_response = await self.ollama_client.generate(
                    model="codellama",
                    prompt=enhanced_prompt
                )
                generated_script = ollama_response.get('response', '')
            except Exception as ollama_error:
                logger.warning(f"Ollama generation failed: {ollama_error}, using template")
                generated_script = self._generate_template_script(message, script_type)
            
            response = f"ðŸ”§ **Generated {script_type} Script**\n\n"
            response += f"```{script_type.lower()}\n{generated_script}\n```\n\n"
            response += "**Next Steps:**\n"
            response += "â€¢ Review and test the script in a safe environment\n"
            response += "â€¢ Modify parameters as needed for your targets\n"
            response += "â€¢ Create an automation job to execute this script\n"
            response += "â€¢ Schedule for recurring execution if needed"
            
            return {
                "response": response,
                "intent": "script_generation",
                "success": True,
                "data": {
                    "script_type": script_type,
                    "script_content": generated_script,
                    "generated_by": "ollama" if 'ollama_response' in locals() else "template"
                }
            }
            
        except Exception as e:
            logger.error(f"Script generation error: {e}")
            return {
                "response": f"âŒ Error generating script: {str(e)}",
                "intent": "script_generation",
                "success": False
            }
    
    def _generate_template_script(self, message: str, script_type: str) -> str:
        """Generate template script when Ollama is unavailable"""
        if script_type == "PowerShell":
            return """# OpsConductor Generated PowerShell Script
param(
    [string]$ComputerName = $env:COMPUTERNAME,
    [string]$LogPath = "C:\\Logs\\OpsConductor.log"
)

try {
    Write-Host "Starting OpsConductor automation on $ComputerName"
    
    # Add your automation logic here
    $result = Get-ComputerInfo | Select-Object WindowsProductName, TotalPhysicalMemory
    
    Write-Host "Automation completed successfully"
    $result | Out-String | Write-Host
    
} catch {
    Write-Error "Automation failed: $($_.Exception.Message)"
    exit 1
}"""
        elif script_type == "Bash":
            return """#!/bin/bash
# OpsConductor Generated Bash Script

set -e  # Exit on error

HOSTNAME=$(hostname)
LOG_FILE="/var/log/opsconductor.log"

echo "Starting OpsConductor automation on $HOSTNAME" | tee -a "$LOG_FILE"

# Add your automation logic here
system_info=$(uname -a)
disk_usage=$(df -h)

echo "System Info: $system_info" | tee -a "$LOG_FILE"
echo "Disk Usage:" | tee -a "$LOG_FILE"
echo "$disk_usage" | tee -a "$LOG_FILE"

echo "Automation completed successfully" | tee -a "$LOG_FILE"
"""
        else:  # Python
            return """#!/usr/bin/env python3
# OpsConductor Generated Python Script

import sys
import logging
import platform
from datetime import datetime

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    try:
        logger.info(f"Starting OpsConductor automation on {platform.node()}")
        
        # Add your automation logic here
        system_info = {
            'hostname': platform.node(),
            'system': platform.system(),
            'release': platform.release(),
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"System info collected: {system_info}")
        logger.info("Automation completed successfully")
        
        return 0
        
    except Exception as e:
        logger.error(f"Automation failed: {str(e)}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
"""
    
    async def handle_greeting(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle greeting messages"""
        try:
            targets_count = len(self.system_knowledge.get('targets', []))
            jobs_count = len(self.system_knowledge.get('recent_jobs', []))
            protocols = self.protocol_manager.get_supported_protocols()
            
            response = f"ðŸ‘‹ **Hello! I'm your OpsConductor AI Assistant**\n\n"
            response += f"**System Overview:**\n"
            response += f"â€¢ {targets_count} targets in your infrastructure\n"
            response += f"â€¢ {jobs_count} recent automation jobs\n"
            response += f"â€¢ {len(protocols)} protocols supported: {', '.join(protocols).upper()}\n\n"
            
            response += f"**What I can help you with:**\n"
            response += f"ðŸŒ **Network Monitoring** - SNMP device monitoring and stats\n"
            response += f"ðŸ“§ **Email Alerts** - SMTP notifications and system alerts\n"
            response += f"ðŸ” **Remote Execution** - SSH command execution and scripts\n"
            response += f"ðŸ“¹ **Camera Management** - VAPIX camera control and motion detection\n"
            response += f"âš™ï¸ **Automation** - Create workflows and scheduled tasks\n"
            response += f"ðŸ”§ **Script Generation** - PowerShell, Bash, and Python scripts\n\n"
            
            response += f"ðŸ’¡ **Try asking:**\n"
            response += f"â€¢ \"Show me all Windows 10 targets\"\n"
            response += f"â€¢ \"Check SNMP on network switches\"\n"
            response += f"â€¢ \"Generate a disk space monitoring script\"\n"
            response += f"â€¢ \"Send alert about server status\"\n"
            response += f"â€¢ \"Setup motion detection on cameras\""
            
            return {
                "response": response,
                "intent": "greeting",
                "success": True,
                "data": {
                    "targets_count": targets_count,
                    "jobs_count": jobs_count,
                    "protocols": protocols
                }
            }
            
        except Exception as e:
            logger.error(f"Greeting error: {e}")
            return {
                "response": "ðŸ‘‹ Hello! I'm your OpsConductor AI Assistant. How can I help you today?",
                "intent": "greeting",
                "success": True
            }
    
    async def handle_general_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle general queries using vector search and Ollama"""
        try:
            # Search for relevant context
            relevant_docs = await self.get_relevant_context(message, limit=5)
            
            # Build context for Ollama
            context_text = ""
            if relevant_docs:
                context_text = "Relevant information from knowledge base:\n"
                for doc in relevant_docs:
                    context_text += f"- {doc.get('content', '')[:200]}...\n"
            
            # System information context
            system_context = f"""
OpsConductor System Information:
- Total targets: {len(self.system_knowledge.get('targets', []))}
- Recent jobs: {len(self.system_knowledge.get('recent_jobs', []))}
- Supported protocols: {', '.join(self.protocol_manager.get_supported_protocols())}
"""
            
            # Generate response using Ollama
            try:
                enhanced_prompt = f"""
You are the OpsConductor AI Assistant. Answer the following question based on the context provided.

Question: {message}

{context_text}

{system_context}

Provide a helpful, accurate response. If you don't have enough information, suggest what the user can do next.
"""
                
                ollama_response = await self.ollama_client.generate(
                    model="llama2",
                    prompt=enhanced_prompt
                )
                ai_response = ollama_response.get('response', '')
            except Exception as ollama_error:
                logger.warning(f"Ollama query failed: {ollama_error}")
                ai_response = "I understand you're asking about OpsConductor operations. Could you be more specific about what you'd like to know? I can help with targets, automation, protocols (SNMP, SMTP, SSH, VAPIX), or script generation."
            
            return {
                "response": ai_response,
                "intent": "general_query",
                "success": True,
                "data": {
                    "context_docs": len(relevant_docs),
                    "generated_by": "ollama" if 'ollama_response' in locals() else "fallback"
                }
            }
            
        except Exception as e:
            logger.error(f"General query error: {e}")
            return {
                "response": f"I encountered an error processing your query: {str(e)}. Please try rephrasing your question.",
                "intent": "general_query",
                "success": False
            }
    
    async def execute_protocol_command(self, protocol: str, target: Dict[str, Any], 
                                     command: str, credentials: Dict[str, Any], **kwargs) -> ProtocolResult:
        """Execute protocol command directly"""
        try:
            return await self.protocol_manager.execute(protocol, target, command, credentials=credentials, **kwargs)
        except Exception as e:
            logger.error(f"Protocol execution error: {e}")
            return ProtocolResult(False, error=str(e))
    
    async def get_protocol_status(self) -> Dict[str, Any]:
        """Get status of all protocol handlers"""
        try:
            protocols = self.protocol_manager.get_supported_protocols()
            status = {
                "supported_protocols": protocols,
                "active_connections": len(self.protocol_manager.active_connections),
                "capabilities": {}
            }
            
            for protocol in protocols:
                status["capabilities"][protocol] = self.protocol_manager.get_protocol_capabilities(protocol)
            
            return status
            
        except Exception as e:
            logger.error(f"Protocol status error: {e}")
            return {"error": str(e)}
    
    async def store_knowledge(self, content: str, category: str = "general") -> bool:
        """Store new knowledge in vector database"""
        try:
            if self.vector_store:
                await self.vector_store.store_knowledge(content, {"category": category})
                return True
            return False
        except Exception as e:
            logger.error(f"Knowledge storage error: {e}")
            return False
    
    async def get_knowledge_stats(self) -> Dict[str, Any]:
        """Get knowledge base statistics"""
        try:
            if self.vector_store:
                return await self.vector_store.get_stats()
            return {"error": "Vector store not available"}
        except Exception as e:
            logger.error(f"Knowledge stats error: {e}")
            return {"error": str(e)}
    
    async def handle_user_recommendations(self, user_id: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle user recommendation requests"""
        try:
            # Get personalized recommendations from learning engine
            recommendations = await self.learning_engine.get_user_recommendations(user_id)
            
            if not recommendations:
                response = f"ðŸŽ¯ **Personalized Recommendations for User {user_id}**\n\n"
                response += "I'm still learning your patterns! Here are some general suggestions:\n\n"
                response += "ðŸ“Š **Get Started:**\n"
                response += "â€¢ Try different automation operations to help me learn your preferences\n"
                response += "â€¢ Use consistent naming patterns for better organization\n"
                response += "â€¢ Schedule regular maintenance tasks\n\n"
                response += "ðŸ”§ **Best Practices:**\n"
                response += "â€¢ Test operations on a small set of targets first\n"
                response += "â€¢ Monitor system performance during peak hours\n"
                response += "â€¢ Keep your automation scripts updated\n\n"
                response += "ðŸ’¡ **Tip:** The more you use the system, the better my recommendations become!"
            else:
                response = f"ðŸŽ¯ **Personalized Recommendations for User {user_id}**\n\n"
                
                high_priority = [r for r in recommendations if r.get('priority') == 'high']
                medium_priority = [r for r in recommendations if r.get('priority') == 'medium']
                low_priority = [r for r in recommendations if r.get('priority') == 'low']
                
                if high_priority:
                    response += "ðŸ”´ **High Priority:**\n"
                    for rec in high_priority:
                        response += f"â€¢ **{rec['title']}**\n"
                        response += f"  {rec['description']}\n"
                        for action in rec.get('suggested_actions', []):
                            response += f"  - {action}\n"
                        response += "\n"
                
                if medium_priority:
                    response += "ðŸŸ¡ **Medium Priority:**\n"
                    for rec in medium_priority:
                        response += f"â€¢ **{rec['title']}**\n"
                        response += f"  {rec['description']}\n"
                        for action in rec.get('suggested_actions', []):
                            response += f"  - {action}\n"
                        response += "\n"
                
                if low_priority:
                    response += "ðŸŸ¢ **Suggestions:**\n"
                    for rec in low_priority:
                        response += f"â€¢ **{rec['title']}**\n"
                        response += f"  {rec['description']}\n"
                        response += "\n"
            
            return {
                "response": response,
                "intent": "recommendations",
                "success": True,
                "data": {
                    "recommendations": recommendations,
                    "user_id": user_id
                }
            }
            
        except Exception as e:
            logger.error(f"Recommendations error: {e}")
            return {
                "response": f"I encountered an error getting your recommendations: {str(e)}",
                "intent": "recommendations",
                "success": False
            }
    
    async def handle_system_health_query(self, context: List[Dict]) -> Dict[str, Any]:
        """Handle system health and anomaly queries"""
        try:
            # Get system health insights from learning engine
            health_insights = await self.learning_engine.get_system_health_insights()
            
            # Get learning engine stats
            learning_stats = await self.learning_engine.get_learning_stats()
            
            response = f"ðŸ¥ **System Health Report**\n\n"
            
            # Overall health status
            health_emoji = {
                'good': 'ðŸŸ¢',
                'fair': 'ðŸŸ¡', 
                'degraded': 'ðŸŸ ',
                'critical': 'ðŸ”´',
                'unknown': 'âšª'
            }
            
            risk_emoji = {
                'low': 'ðŸŸ¢',
                'medium': 'ðŸŸ¡',
                'high': 'ðŸ”´',
                'unknown': 'âšª'
            }
            
            overall_health = health_insights.get('overall_health', 'unknown')
            risk_level = health_insights.get('risk_level', 'unknown')
            
            response += f"**Overall Status:** {health_emoji.get(overall_health, 'âšª')} {overall_health.title()}\n"
            response += f"**Risk Level:** {risk_emoji.get(risk_level, 'âšª')} {risk_level.title()}\n\n"
            
            # Active anomalies
            active_anomalies = health_insights.get('active_anomalies', [])
            if active_anomalies:
                response += f"ðŸš¨ **Active Anomalies ({len(active_anomalies)}):**\n"
                for anomaly in active_anomalies[:5]:  # Show top 5
                    severity_emoji = {'low': 'ðŸŸ¡', 'medium': 'ðŸŸ ', 'high': 'ðŸ”´', 'critical': 'ðŸš¨'}
                    response += f"â€¢ {severity_emoji.get(anomaly['severity'], 'âšª')} **{anomaly['type'].replace('_', ' ').title()}**\n"
                    response += f"  {anomaly['description']}\n"
                    response += f"  *Confidence: {anomaly['confidence']:.1%}*\n\n"
                
                if len(active_anomalies) > 5:
                    response += f"  ... and {len(active_anomalies) - 5} more anomalies\n\n"
            else:
                response += f"âœ… **No Active Anomalies**\n\n"
            
            # System metrics
            metrics = health_insights.get('metrics_summary', {})
            if metrics:
                response += f"ðŸ“Š **System Metrics (Last Hour):**\n"
                if 'cpu_usage' in metrics:
                    response += f"â€¢ CPU Usage: {metrics['cpu_usage']:.1f}%\n"
                if 'memory_usage' in metrics:
                    response += f"â€¢ Memory Usage: {metrics['memory_usage']:.1f}%\n"
                if 'response_time' in metrics:
                    response += f"â€¢ Avg Response Time: {metrics['response_time']:.2f}ms\n"
                if 'error_rate' in metrics:
                    response += f"â€¢ Error Rate: {metrics['error_rate']:.2%}\n"
                response += "\n"
            
            # Learning system status
            response += f"ðŸ§  **AI Learning System:**\n"
            response += f"â€¢ Execution Records: {learning_stats.get('execution_records', 0):,}\n"
            response += f"â€¢ User Patterns: {learning_stats.get('user_patterns', 0)}\n"
            response += f"â€¢ Predictions Made: {learning_stats.get('predictions_made', 0)}\n"
            response += f"â€¢ Learning Status: {learning_stats.get('learning_status', 'unknown').title()}\n\n"
            
            # Recommendations
            recommendations = health_insights.get('recommendations', [])
            if recommendations:
                response += f"ðŸ’¡ **Recommendations:**\n"
                for rec in recommendations:
                    response += f"â€¢ {rec}\n"
            
            return {
                "response": response,
                "intent": "system_health",
                "success": True,
                "data": {
                    "health_insights": health_insights,
                    "learning_stats": learning_stats
                }
            }
            
        except Exception as e:
            logger.error(f"System health query error: {e}")
            return {
                "response": f"I encountered an error checking system health: {str(e)}",
                "intent": "system_health", 
                "success": False
            }
    
    async def handle_target_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about targets, including filtering by tags, OS, etc."""
        try:
            message_lower = message.lower()
            targets = self.system_knowledge.get('targets', [])
            enhanced_targets = self.system_knowledge.get('enhanced_targets', [])
            
            # Combine all targets for analysis
            all_targets = targets + enhanced_targets
            
            if not all_targets:
                return {
                    "response": "ðŸ” No targets found in your infrastructure. Please add some targets first.",
                    "intent": "query_targets",
                    "success": False
                }
            
            # Parse the query to understand what the user is looking for
            filtered_targets = []
            filter_description = ""
            
            # Check for Windows 10 queries
            if any(term in message_lower for term in ['windows 10', 'win10', 'windows10']):
                # Look for targets with win10 tag or Windows 10 in OS field
                for target in all_targets:
                    tags = str(target.get('tags', '')).lower()
                    os_info = str(target.get('os', '')).lower()
                    os_name = str(target.get('os_name', '')).lower()
                    
                    if ('win10' in tags or 'windows 10' in tags or 
                        'windows 10' in os_info or 'win10' in os_info or
                        'windows 10' in os_name or 'win10' in os_name):
                        filtered_targets.append(target)
                
                filter_description = "Windows 10 (win10 tag or OS)"
            
            # Check for other Windows versions
            elif any(term in message_lower for term in ['windows', 'win']):
                for target in all_targets:
                    tags = str(target.get('tags', '')).lower()
                    os_info = str(target.get('os', '')).lower()
                    os_name = str(target.get('os_name', '')).lower()
                    
                    if ('windows' in tags or 'win' in tags or 
                        'windows' in os_info or 'win' in os_info or
                        'windows' in os_name or 'win' in os_name):
                        filtered_targets.append(target)
                
                filter_description = "Windows systems"
            
            # Check for Linux queries
            elif any(term in message_lower for term in ['linux', 'ubuntu', 'centos', 'rhel']):
                for target in all_targets:
                    tags = str(target.get('tags', '')).lower()
                    os_info = str(target.get('os', '')).lower()
                    os_name = str(target.get('os_name', '')).lower()
                    
                    if any(linux_term in tags or linux_term in os_info or linux_term in os_name 
                           for linux_term in ['linux', 'ubuntu', 'centos', 'rhel']):
                        filtered_targets.append(target)
                
                filter_description = "Linux systems"
            
            # Check for specific tags
            elif 'tag' in message_lower:
                # Extract tag name from message
                import re
                tag_match = re.search(r'tag[:\s]+([a-zA-Z0-9_-]+)', message_lower)
                if tag_match:
                    tag_name = tag_match.group(1)
                    for target in all_targets:
                        tags = str(target.get('tags', '')).lower()
                        if tag_name in tags:
                            filtered_targets.append(target)
                    filter_description = f"tag '{tag_name}'"
            
            # Check for server/workstation queries
            elif any(term in message_lower for term in ['server', 'servers']):
                for target in all_targets:
                    tags = str(target.get('tags', '')).lower()
                    hostname = str(target.get('hostname', '')).lower()
                    
                    if 'server' in tags or 'server' in hostname:
                        filtered_targets.append(target)
                
                filter_description = "servers"
            
            # Default: show all targets
            else:
                filtered_targets = all_targets
                filter_description = "all targets"
            
            # Build response
            if not filtered_targets:
                response = f"ðŸ” **No targets found matching '{filter_description}'**\n\n"
                response += f"**Total targets in system:** {len(all_targets)}\n\n"
                response += "**Try searching for:**\n"
                response += "â€¢ 'Windows 10 targets' or 'win10 targets'\n"
                response += "â€¢ 'Linux targets' or 'Ubuntu targets'\n"
                response += "â€¢ 'servers' or 'workstations'\n"
                response += "â€¢ 'targets with tag [tagname]'\n"
                response += "â€¢ 'all targets' to see everything"
            else:
                response = f"ðŸŽ¯ **Found {len(filtered_targets)} targets matching '{filter_description}'**\n\n"
                
                # Show target details
                for i, target in enumerate(filtered_targets[:10]):  # Show first 10
                    hostname = target.get('hostname', 'Unknown')
                    ip = target.get('ip_address', 'No IP')
                    os_info = target.get('os', target.get('os_name', 'Unknown OS'))
                    tags = target.get('tags', 'No tags')
                    
                    response += f"**{i+1}. {hostname}**\n"
                    response += f"   â€¢ IP: {ip}\n"
                    response += f"   â€¢ OS: {os_info}\n"
                    response += f"   â€¢ Tags: {tags}\n\n"
                
                if len(filtered_targets) > 10:
                    response += f"... and {len(filtered_targets) - 10} more targets\n\n"
                
                response += f"**Summary:**\n"
                response += f"â€¢ Total matching: {len(filtered_targets)}\n"
                response += f"â€¢ Total in system: {len(all_targets)}\n"
                
                # Show OS breakdown for filtered targets
                os_counts = {}
                for target in filtered_targets:
                    os_info = target.get('os', target.get('os_name', 'Unknown'))
                    os_counts[os_info] = os_counts.get(os_info, 0) + 1
                
                if os_counts:
                    response += f"\n**OS Breakdown:**\n"
                    for os_name, count in sorted(os_counts.items()):
                        response += f"â€¢ {os_name}: {count}\n"
            
            return {
                "response": response,
                "intent": "query_targets",
                "success": True,
                "data": {
                    "filtered_targets": len(filtered_targets),
                    "total_targets": len(all_targets),
                    "filter_description": filter_description,
                    "targets": filtered_targets[:10]  # Return first 10 for API consumers
                }
            }
            
        except Exception as e:
            logger.error(f"Target query error: {e}")
            return {
                "response": f"âŒ Error querying targets: {str(e)}",
                "intent": "query_targets",
                "success": False
            }
    
    async def handle_job_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about automation jobs"""
        try:
            jobs = self.system_knowledge.get('recent_jobs', [])
            
            if not jobs:
                return {
                    "response": "ðŸ“‹ No automation jobs found in the system.",
                    "intent": "query_jobs",
                    "success": True,
                    "data": {"jobs_count": 0}
                }
            
            message_lower = message.lower()
            
            # Filter jobs based on query
            if 'recent' in message_lower or 'latest' in message_lower:
                filtered_jobs = jobs[:5]  # Most recent 5
                filter_desc = "recent"
            elif 'failed' in message_lower or 'error' in message_lower:
                filtered_jobs = [j for j in jobs if j.get('status') in ['failed', 'error']]
                filter_desc = "failed"
            elif 'running' in message_lower or 'active' in message_lower:
                filtered_jobs = [j for j in jobs if j.get('status') in ['running', 'active', 'in_progress']]
                filter_desc = "running"
            elif 'completed' in message_lower or 'success' in message_lower:
                filtered_jobs = [j for j in jobs if j.get('status') in ['completed', 'success', 'finished']]
                filter_desc = "completed"
            else:
                filtered_jobs = jobs[:10]  # Show first 10
                filter_desc = "all"
            
            response = f"ðŸ“‹ **Automation Jobs ({filter_desc})**\n\n"
            
            if not filtered_jobs:
                response += f"No {filter_desc} jobs found.\n"
                response += f"Total jobs in system: {len(jobs)}"
            else:
                for i, job in enumerate(filtered_jobs[:5]):  # Show max 5
                    job_id = job.get('id', 'Unknown')
                    description = job.get('description', 'No description')
                    status = job.get('status', 'Unknown')
                    created_at = job.get('created_at', 'Unknown')
                    
                    status_emoji = {
                        'completed': 'âœ…', 'success': 'âœ…', 'finished': 'âœ…',
                        'failed': 'âŒ', 'error': 'âŒ',
                        'running': 'ðŸ”„', 'active': 'ðŸ”„', 'in_progress': 'ðŸ”„',
                        'pending': 'â³', 'queued': 'â³'
                    }
                    
                    emoji = status_emoji.get(status.lower(), 'ðŸ“‹')
                    
                    response += f"**{i+1}. Job #{job_id}** {emoji}\n"
                    response += f"   â€¢ Description: {description[:100]}{'...' if len(description) > 100 else ''}\n"
                    response += f"   â€¢ Status: {status}\n"
                    response += f"   â€¢ Created: {created_at}\n\n"
                
                if len(filtered_jobs) > 5:
                    response += f"... and {len(filtered_jobs) - 5} more {filter_desc} jobs\n\n"
                
                response += f"**Summary:** {len(filtered_jobs)} {filter_desc} jobs, {len(jobs)} total"
            
            return {
                "response": response,
                "intent": "query_jobs",
                "success": True,
                "data": {
                    "filtered_jobs": len(filtered_jobs),
                    "total_jobs": len(jobs),
                    "filter_description": filter_desc
                }
            }
            
        except Exception as e:
            logger.error(f"Job query error: {e}")
            return {
                "response": f"âŒ Error querying jobs: {str(e)}",
                "intent": "query_jobs",
                "success": False
            }
    
    async def handle_target_group_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about target groups"""
        try:
            # Get target groups from asset service
            target_groups = await self.asset_client.get_target_groups()
            
            if not target_groups:
                return {
                    "response": "ðŸ” **No target groups found**\n\nYour system doesn't have any target groups configured yet. You can create target groups to organize your infrastructure targets.",
                    "intent": "query_target_groups",
                    "success": True,
                    "data": {"groups_count": 0}
                }
            
            message_lower = message.lower()
            
            # Check if asking for specific group details
            if any(word in message_lower for word in ['details', 'targets in', 'members']):
                # Try to extract group name
                for group in target_groups:
                    group_name = group.get('name', '').lower()
                    if group_name in message_lower:
                        # Get targets in this specific group
                        targets = await self.asset_client.get_targets_in_group(group['id'])
                        
                        response = f"ðŸŽ¯ **Target Group: {group['name']}**\n\n"
                        response += f"**Description:** {group.get('description', 'No description')}\n"
                        response += f"**Targets:** {len(targets)}\n\n"
                        
                        if targets:
                            response += "**Group Members:**\n"
                            for i, target in enumerate(targets[:10]):  # Show first 10
                                hostname = target.get('hostname', 'Unknown')
                                ip = target.get('ip_address', 'No IP')
                                os_info = target.get('os_type', target.get('os', 'Unknown OS'))
                                response += f"{i+1}. **{hostname}** ({ip}) - {os_info}\n"
                            
                            if len(targets) > 10:
                                response += f"... and {len(targets) - 10} more targets\n"
                        else:
                            response += "**No targets in this group yet.**\n"
                        
                        return {
                            "response": response,
                            "intent": "query_target_groups",
                            "success": True,
                            "data": {
                                "group": group,
                                "targets_count": len(targets),
                                "targets": targets[:10]
                            }
                        }
            
            # General target groups overview
            response = f"ðŸ“ **Target Groups Overview**\n\n"
            response += f"**Total Groups:** {len(target_groups)}\n\n"
            
            # Show each group with summary
            for i, group in enumerate(target_groups):
                group_name = group.get('name', 'Unnamed Group')
                description = group.get('description', 'No description')
                
                # Get target count for this group
                targets = await self.asset_client.get_targets_in_group(group['id'])
                target_count = len(targets)
                
                response += f"**{i+1}. {group_name}**\n"
                response += f"   â€¢ Description: {description}\n"
                response += f"   â€¢ Targets: {target_count}\n"
                response += f"   â€¢ ID: {group['id']}\n\n"
            
            response += "ðŸ’¡ **Tip:** Ask 'Show me targets in [group name]' for detailed group information."
            
            return {
                "response": response,
                "intent": "query_target_groups",
                "success": True,
                "data": {
                    "groups_count": len(target_groups),
                    "groups": target_groups
                }
            }
            
        except Exception as e:
            logger.error(f"Target group query error: {e}")
            return {
                "response": f"âŒ Error querying target groups: {str(e)}",
                "intent": "query_target_groups",
                "success": False
            }
    
    async def handle_workflow_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about workflows and automation templates"""
        try:
            # Get workflows from automation service
            workflows = await self.automation_client.list_ai_jobs(limit=100)
            
            message_lower = message.lower()
            
            # Filter workflows based on query
            if 'ai' in message_lower or 'ai-generated' in message_lower:
                filtered_workflows = [w for w in workflows if w.get('job_type') == 'ai_generated']
                filter_desc = "AI-generated"
            elif 'template' in message_lower:
                filtered_workflows = [w for w in workflows if 'template' in w.get('name', '').lower()]
                filter_desc = "template"
            elif 'scheduled' in message_lower:
                filtered_workflows = [w for w in workflows if w.get('is_scheduled', False)]
                filter_desc = "scheduled"
            else:
                filtered_workflows = workflows
                filter_desc = "all"
            
            if not filtered_workflows:
                response = f"ðŸ“‹ **No {filter_desc} workflows found**\n\n"
                if workflows:
                    response += f"Total workflows in system: {len(workflows)}\n\n"
                    response += "**Available workflow types:**\n"
                    types = set(w.get('job_type', 'unknown') for w in workflows)
                    for wf_type in types:
                        count = len([w for w in workflows if w.get('job_type') == wf_type])
                        response += f"â€¢ {wf_type}: {count} workflows\n"
                else:
                    response += "No workflows have been created yet. You can create workflows through automation or ask the AI to generate them."
                
                return {
                    "response": response,
                    "intent": "query_workflows",
                    "success": True,
                    "data": {"workflows_count": 0, "total_workflows": len(workflows)}
                }
            
            response = f"âš™ï¸ **{filter_desc.title()} Workflows**\n\n"
            response += f"**Found:** {len(filtered_workflows)} workflows\n\n"
            
            # Show workflow details
            for i, workflow in enumerate(filtered_workflows[:10]):  # Show first 10
                name = workflow.get('name', 'Unnamed Workflow')
                description = workflow.get('description', 'No description')
                job_type = workflow.get('job_type', 'unknown')
                is_enabled = workflow.get('is_enabled', False)
                created_at = workflow.get('created_at', 'Unknown')
                
                status_emoji = 'âœ…' if is_enabled else 'â¸ï¸'
                
                response += f"**{i+1}. {name}** {status_emoji}\n"
                response += f"   â€¢ Type: {job_type}\n"
                response += f"   â€¢ Description: {description[:100]}{'...' if len(description) > 100 else ''}\n"
                response += f"   â€¢ Status: {'Enabled' if is_enabled else 'Disabled'}\n"
                response += f"   â€¢ Created: {created_at}\n\n"
            
            if len(filtered_workflows) > 10:
                response += f"... and {len(filtered_workflows) - 10} more workflows\n\n"
            
            response += f"**Summary:** {len(filtered_workflows)} {filter_desc} workflows, {len(workflows)} total"
            
            return {
                "response": response,
                "intent": "query_workflows",
                "success": True,
                "data": {
                    "filtered_workflows": len(filtered_workflows),
                    "total_workflows": len(workflows),
                    "filter_description": filter_desc,
                    "workflows": filtered_workflows[:10]
                }
            }
            
        except Exception as e:
            logger.error(f"Workflow query error: {e}")
            return {
                "response": f"âŒ Error querying workflows: {str(e)}",
                "intent": "query_workflows",
                "success": False
            }
    
    async def handle_execution_history_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about execution history"""
        try:
            # For now, use the recent jobs from system knowledge
            # In a full implementation, this would query the automation service for execution history
            jobs = self.system_knowledge.get('recent_jobs', [])
            
            if not jobs:
                return {
                    "response": "ðŸ“‹ **No execution history found**\n\nNo job executions have been recorded yet. Start running some automation jobs to see execution history here.",
                    "intent": "query_execution_history",
                    "success": True,
                    "data": {"executions_count": 0}
                }
            
            message_lower = message.lower()
            
            # Time-based filtering
            if 'today' in message_lower:
                # Filter for today's executions (simplified)
                filtered_jobs = jobs[:5]  # Most recent 5 as proxy
                filter_desc = "today's"
            elif 'yesterday' in message_lower:
                filtered_jobs = jobs[5:10] if len(jobs) > 5 else []
                filter_desc = "yesterday's"
            elif 'week' in message_lower or 'last week' in message_lower:
                filtered_jobs = jobs[:20]  # Last 20 as proxy for week
                filter_desc = "this week's"
            elif 'month' in message_lower:
                filtered_jobs = jobs  # All available
                filter_desc = "this month's"
            else:
                filtered_jobs = jobs[:15]  # Recent 15
                filter_desc = "recent"
            
            if not filtered_jobs:
                return {
                    "response": f"ðŸ“‹ **No {filter_desc} executions found**\n\nTotal executions in system: {len(jobs)}",
                    "intent": "query_execution_history",
                    "success": True,
                    "data": {"executions_count": 0, "total_executions": len(jobs)}
                }
            
            response = f"ðŸ“Š **Execution History ({filter_desc})**\n\n"
            response += f"**Found:** {len(filtered_jobs)} executions\n\n"
            
            # Execution statistics
            statuses = {}
            for job in filtered_jobs:
                status = job.get('status', 'unknown')
                statuses[status] = statuses.get(status, 0) + 1
            
            response += "**Status Summary:**\n"
            for status, count in statuses.items():
                emoji = {
                    'completed': 'âœ…', 'success': 'âœ…', 'finished': 'âœ…',
                    'failed': 'âŒ', 'error': 'âŒ',
                    'running': 'ðŸ”„', 'active': 'ðŸ”„', 'in_progress': 'ðŸ”„',
                    'pending': 'â³', 'queued': 'â³'
                }.get(status.lower(), 'ðŸ“‹')
                response += f"â€¢ {emoji} {status}: {count}\n"
            
            response += "\n**Recent Executions:**\n"
            
            # Show execution details
            for i, job in enumerate(filtered_jobs[:8]):  # Show first 8
                job_id = job.get('id', 'Unknown')
                description = job.get('description', 'No description')
                status = job.get('status', 'Unknown')
                created_at = job.get('created_at', 'Unknown')
                duration = job.get('duration', 'Unknown')
                
                status_emoji = {
                    'completed': 'âœ…', 'success': 'âœ…', 'finished': 'âœ…',
                    'failed': 'âŒ', 'error': 'âŒ',
                    'running': 'ðŸ”„', 'active': 'ðŸ”„', 'in_progress': 'ðŸ”„',
                    'pending': 'â³', 'queued': 'â³'
                }.get(status.lower(), 'ðŸ“‹')
                
                response += f"**{i+1}. Execution #{job_id}** {status_emoji}\n"
                response += f"   â€¢ Job: {description[:80]}{'...' if len(description) > 80 else ''}\n"
                response += f"   â€¢ Status: {status}\n"
                response += f"   â€¢ Started: {created_at}\n"
                if duration != 'Unknown':
                    response += f"   â€¢ Duration: {duration}\n"
                response += "\n"
            
            if len(filtered_jobs) > 8:
                response += f"... and {len(filtered_jobs) - 8} more executions\n\n"
            
            # Success rate calculation
            completed = statuses.get('completed', 0) + statuses.get('success', 0) + statuses.get('finished', 0)
            failed = statuses.get('failed', 0) + statuses.get('error', 0)
            total_finished = completed + failed
            
            if total_finished > 0:
                success_rate = (completed / total_finished) * 100
                response += f"**Success Rate:** {success_rate:.1f}% ({completed}/{total_finished} successful)"
            
            return {
                "response": response,
                "intent": "query_execution_history",
                "success": True,
                "data": {
                    "executions_count": len(filtered_jobs),
                    "total_executions": len(jobs),
                    "filter_description": filter_desc,
                    "status_summary": statuses,
                    "success_rate": success_rate if total_finished > 0 else None
                }
            }
            
        except Exception as e:
            logger.error(f"Execution history query error: {e}")
            return {
                "response": f"âŒ Error querying execution history: {str(e)}",
                "intent": "query_execution_history",
                "success": False
            }
    
    async def handle_performance_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about system performance and metrics"""
        try:
            # Get performance data from learning engine and system knowledge
            learning_stats = await self.learning_engine.get_learning_stats()
            health_insights = await self.learning_engine.get_system_health_insights()
            
            targets_count = len(self.system_knowledge.get('targets', []))
            jobs_count = len(self.system_knowledge.get('recent_jobs', []))
            
            response = f"ðŸ“Š **System Performance Metrics**\n\n"
            
            # System overview
            response += f"**Infrastructure Overview:**\n"
            response += f"â€¢ Total Targets: {targets_count}\n"
            response += f"â€¢ Total Jobs: {jobs_count}\n"
            response += f"â€¢ Supported Protocols: {len(self.protocol_manager.get_supported_protocols())}\n\n"
            
            # AI Learning Performance
            response += f"ðŸ§  **AI Learning Performance:**\n"
            response += f"â€¢ Execution Records: {learning_stats.get('execution_records', 0):,}\n"
            response += f"â€¢ User Patterns: {learning_stats.get('user_patterns', 0)}\n"
            response += f"â€¢ Predictions Made: {learning_stats.get('predictions_made', 0)}\n"
            response += f"â€¢ Learning Status: {learning_stats.get('learning_status', 'unknown').title()}\n\n"
            
            # System Health Metrics
            metrics = health_insights.get('metrics_summary', {})
            if metrics:
                response += f"âš¡ **System Metrics:**\n"
                if 'cpu_usage' in metrics:
                    response += f"â€¢ CPU Usage: {metrics['cpu_usage']:.1f}%\n"
                if 'memory_usage' in metrics:
                    response += f"â€¢ Memory Usage: {metrics['memory_usage']:.1f}%\n"
                if 'response_time' in metrics:
                    response += f"â€¢ Avg Response Time: {metrics['response_time']:.2f}ms\n"
                if 'error_rate' in metrics:
                    response += f"â€¢ Error Rate: {metrics['error_rate']:.2%}\n"
                response += "\n"
            
            # Job Performance Analysis
            jobs = self.system_knowledge.get('recent_jobs', [])
            if jobs:
                statuses = {}
                for job in jobs:
                    status = job.get('status', 'unknown')
                    statuses[status] = statuses.get(status, 0) + 1
                
                completed = statuses.get('completed', 0) + statuses.get('success', 0)
                failed = statuses.get('failed', 0) + statuses.get('error', 0)
                total_finished = completed + failed
                
                response += f"ðŸŽ¯ **Job Performance:**\n"
                response += f"â€¢ Total Jobs: {len(jobs)}\n"
                response += f"â€¢ Completed: {completed}\n"
                response += f"â€¢ Failed: {failed}\n"
                
                if total_finished > 0:
                    success_rate = (completed / total_finished) * 100
                    response += f"â€¢ Success Rate: {success_rate:.1f}%\n"
                
                response += "\n"
            
            # Protocol Performance
            protocols = self.protocol_manager.get_supported_protocols()
            response += f"ðŸ”Œ **Protocol Status:**\n"
            for protocol in protocols:
                capabilities = self.protocol_manager.get_protocol_capabilities(protocol)
                response += f"â€¢ {protocol.upper()}: {len(capabilities)} capabilities\n"
            
            response += f"\nðŸ’¡ **Performance Tips:**\n"
            response += f"â€¢ Monitor success rates regularly\n"
            response += f"â€¢ Review failed jobs for patterns\n"
            response += f"â€¢ Keep target credentials updated\n"
            response += f"â€¢ Use AI recommendations for optimization"
            
            return {
                "response": response,
                "intent": "query_performance",
                "success": True,
                "data": {
                    "targets_count": targets_count,
                    "jobs_count": jobs_count,
                    "learning_stats": learning_stats,
                    "metrics": metrics,
                    "protocols_count": len(protocols)
                }
            }
            
        except Exception as e:
            logger.error(f"Performance query error: {e}")
            return {
                "response": f"âŒ Error querying performance metrics: {str(e)}",
                "intent": "query_performance",
                "success": False
            }
    
    async def handle_error_analysis_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about errors and failure analysis"""
        try:
            jobs = self.system_knowledge.get('recent_jobs', [])
            
            # Filter for failed jobs
            failed_jobs = [job for job in jobs if job.get('status') in ['failed', 'error']]
            
            if not failed_jobs:
                return {
                    "response": "âœ… **No Recent Errors Found**\n\nGreat news! No failed jobs found in recent history. Your automation is running smoothly.",
                    "intent": "query_error_analysis",
                    "success": True,
                    "data": {"error_count": 0, "total_jobs": len(jobs)}
                }
            
            response = f"ðŸ” **Error Analysis Report**\n\n"
            response += f"**Failed Jobs:** {len(failed_jobs)} out of {len(jobs)} total\n\n"
            
            # Error pattern analysis
            error_patterns = {}
            error_types = {}
            
            for job in failed_jobs:
                # Analyze error messages for patterns
                error_msg = job.get('error_message', 'Unknown error')
                
                # Common error categorization
                if 'connection' in error_msg.lower() or 'timeout' in error_msg.lower():
                    error_types['Connection Issues'] = error_types.get('Connection Issues', 0) + 1
                elif 'permission' in error_msg.lower() or 'access' in error_msg.lower():
                    error_types['Permission Errors'] = error_types.get('Permission Errors', 0) + 1
                elif 'credential' in error_msg.lower() or 'auth' in error_msg.lower():
                    error_types['Authentication Errors'] = error_types.get('Authentication Errors', 0) + 1
                elif 'not found' in error_msg.lower() or '404' in error_msg:
                    error_types['Resource Not Found'] = error_types.get('Resource Not Found', 0) + 1
                else:
                    error_types['Other Errors'] = error_types.get('Other Errors', 0) + 1
            
            # Show error type breakdown
            response += f"**Error Categories:**\n"
            for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / len(failed_jobs)) * 100
                response += f"â€¢ {error_type}: {count} ({percentage:.1f}%)\n"
            
            response += f"\n**Recent Failed Jobs:**\n"
            
            # Show recent failed jobs
            for i, job in enumerate(failed_jobs[:5]):  # Show first 5 failed jobs
                job_id = job.get('id', 'Unknown')
                description = job.get('description', 'No description')
                error_msg = job.get('error_message', 'No error message')
                failed_at = job.get('failed_at', job.get('created_at', 'Unknown'))
                
                response += f"**{i+1}. Job #{job_id}** âŒ\n"
                response += f"   â€¢ Description: {description[:80]}{'...' if len(description) > 80 else ''}\n"
                response += f"   â€¢ Error: {error_msg[:100]}{'...' if len(error_msg) > 100 else ''}\n"
                response += f"   â€¢ Failed At: {failed_at}\n\n"
            
            if len(failed_jobs) > 5:
                response += f"... and {len(failed_jobs) - 5} more failed jobs\n\n"
            
            # Recommendations
            response += f"ðŸ”§ **Recommended Actions:**\n"
            
            if error_types.get('Connection Issues', 0) > 0:
                response += f"â€¢ Check network connectivity to targets\n"
                response += f"â€¢ Verify target availability and firewall settings\n"
            
            if error_types.get('Permission Errors', 0) > 0:
                response += f"â€¢ Review user permissions on target systems\n"
                response += f"â€¢ Ensure service accounts have required privileges\n"
            
            if error_types.get('Authentication Errors', 0) > 0:
                response += f"â€¢ Update expired credentials\n"
                response += f"â€¢ Verify authentication configuration\n"
            
            if error_types.get('Resource Not Found', 0) > 0:
                response += f"â€¢ Check if target resources still exist\n"
                response += f"â€¢ Update automation scripts for path changes\n"
            
            response += f"â€¢ Review and retry failed jobs after fixes\n"
            response += f"â€¢ Monitor error trends over time"
            
            return {
                "response": response,
                "intent": "query_error_analysis",
                "success": True,
                "data": {
                    "error_count": len(failed_jobs),
                    "total_jobs": len(jobs),
                    "error_types": error_types,
                    "failed_jobs": failed_jobs[:5]
                }
            }
            
        except Exception as e:
            logger.error(f"Error analysis query error: {e}")
            return {
                "response": f"âŒ Error analyzing errors: {str(e)}",
                "intent": "query_error_analysis",
                "success": False
            }
    
    async def handle_notification_history_query(self, message: str, context: List[Dict]) -> Dict[str, Any]:
        """Handle queries about notification and communication history"""
        try:
            # For now, return a placeholder response since we don't have direct access to communication service
            # In a full implementation, this would query the communication service
            
            response = f"ðŸ“§ **Notification History**\n\n"
            response += f"**Communication Service Integration:**\n"
            response += f"â€¢ Service Status: Active\n"
            response += f"â€¢ Supported Channels: SMTP Email\n"
            response += f"â€¢ Configuration: Ready\n\n"
            
            response += f"**Recent Activity:**\n"
            response += f"â€¢ System alerts sent for job completions\n"
            response += f"â€¢ Error notifications for failed operations\n"
            response += f"â€¢ Health check alerts for system monitoring\n\n"
            
            response += f"ðŸ“Š **Notification Statistics:**\n"
            response += f"â€¢ Total Notifications: Available via Communication Service\n"
            response += f"â€¢ Delivery Rate: Monitored by SMTP service\n"
            response += f"â€¢ Failed Deliveries: Tracked in communication logs\n\n"
            
            response += f"ðŸ’¡ **To get detailed notification history:**\n"
            response += f"â€¢ Check the Communication Service logs\n"
            response += f"â€¢ Review SMTP delivery reports\n"
            response += f"â€¢ Monitor alert configuration settings\n"
            response += f"â€¢ Use the frontend dashboard for visual reports"
            
            return {
                "response": response,
                "intent": "query_notification_history",
                "success": True,
                "data": {
                    "service_status": "active",
                    "channels": ["smtp"],
                    "integration_ready": True
                }
            }
            
        except Exception as e:
            logger.error(f"Notification history query error: {e}")
            return {
                "response": f"âŒ Error querying notification history: {str(e)}",
                "intent": "query_notification_history",
                "success": False
            }

# Global AI instance
ai_engine = OpsConductorAI()