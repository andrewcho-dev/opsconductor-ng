version: '3.8'

services:
  # Production PostgreSQL with clustering support
  postgres-production:
    image: postgres:17-alpine
    container_name: opsconductor-postgres-prod
    environment:
      POSTGRES_DB: opsconductor
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres123}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./database/complete-schema.sql:/docker-entrypoint-initdb.d/complete-schema.sql
      - ./production/backups:/backups
    ports:
      - "5432:5432"
    networks:
      - opsconductor-prod-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Production Redis with persistence
  redis-production:
    image: redis:7.4-alpine
    container_name: opsconductor-redis-prod
    ports:
      - "6379:6379"
    volumes:
      - redis_prod_data:/data
      - ./redis/redis.production.conf:/usr/local/etc/redis/redis.conf
    networks:
      - opsconductor-prod-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    command: redis-server /usr/local/etc/redis/redis.conf
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Production ChromaDB for AI Knowledge
  chromadb-production:
    image: chromadb/chroma:0.6.1
    container_name: opsconductor-chromadb-prod
    ports:
      - "8000:8000"
    volumes:
      - chromadb_prod_data:/chroma/chroma
      - ./production/data/chromadb:/backups
    networks:
      - opsconductor-prod-net
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_AUTH_PROVIDER=
      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=
      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=
      - ANONYMIZED_TELEMETRY=False
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Production Ollama LLM Server
  ollama-production:
    image: ollama/ollama:0.11.11
    container_name: opsconductor-ollama-prod
    ports:
      - "11434:11434"
    volumes:
      - ollama_prod_models:/root/.ollama
      - ./production/data/ollama:/backups
    networks:
      - opsconductor-prod-net
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_MAX_LOADED_MODELS=3
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # Production Multi-Brain AI System
  ai-brain-production:
    build: 
      context: ./ai-brain
      dockerfile: Dockerfile.production
    container_name: opsconductor-ai-brain-prod
    ports:
      - "3005:3005"
    environment:
      # Production environment
      NODE_ENV: production
      ENVIRONMENT: production
      
      # Database connections
      DB_HOST: postgres-production
      DB_PORT: 5432
      DB_NAME: opsconductor
      DB_USER: postgres
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres123}
      REDIS_URL: redis://redis-production:6379/9
      
      # AI Infrastructure
      CHROMADB_URL: http://chromadb-production:8000
      OLLAMA_HOST: http://ollama-production:11434
      
      # Multi-Brain System Configuration
      MULTI_BRAIN_ENABLED: true
      INTENT_BRAIN_ENABLED: true
      TECHNICAL_BRAIN_ENABLED: true
      SME_BRAIN_ENABLED: true
      ORCHESTRATOR_ENABLED: true
      
      # Production Performance Settings
      MAX_CONCURRENT_REQUESTS: 100
      REQUEST_TIMEOUT: 30000
      BRAIN_PROCESSING_TIMEOUT: 60000
      LEARNING_ENABLED: true
      CONTINUOUS_LEARNING: true
      
      # Resource Management
      MAX_MEMORY_USAGE: 6G
      GPU_MEMORY_FRACTION: 0.8
      
      # Monitoring
      METRICS_ENABLED: true
      PROMETHEUS_METRICS: true
      HEALTH_CHECK_INTERVAL: 30
      
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
      replicas: 1
      
    depends_on:
      postgres-production:
        condition: service_healthy
      redis-production:
        condition: service_healthy
      chromadb-production:
        condition: service_healthy
      ollama-production:
        condition: service_healthy
        
    networks:
      - opsconductor-prod-net
      
    volumes:
      # Production data persistence
      - ./production/data/ai-brain:/app/data
      - ./production/data/chromadb:/app/chromadb_data
      - ./production/logs:/app/logs
      
      # Multi-brain system components
      - ./ai-brain/brains:/app/brains
      - ./ai-brain/orchestration:/app/orchestration
      - ./ai-brain/learning:/app/learning
      - ./ai-brain/intent_brain.py:/app/intent_brain.py
      - ./ai-brain/multibrain_orchestrator.py:/app/multibrain_orchestrator.py
      - ./ai-brain/four_w_analyzer.py:/app/four_w_analyzer.py
      - ./ai-brain/intent_technical_bridge.py:/app/intent_technical_bridge.py
      
      # Core AI Brain files
      - ./ai-brain/main.py:/app/main.py
      - ./ai-brain/brain_engine.py:/app/brain_engine.py
      - ./ai-brain/llm_conversation_handler.py:/app/llm_conversation_handler.py
      
      # AI modules
      - ./ai-brain/system_model:/app/system_model
      - ./ai-brain/knowledge_engine:/app/knowledge_engine
      - ./ai-brain/intent_engine:/app/intent_engine
      - ./ai-brain/job_engine:/app/job_engine
      - ./ai-brain/integrations:/app/integrations
      - ./ai-brain/processing:/app/processing
      - ./ai-brain/api:/app/api
      - ./ai-brain/analytics:/app/analytics
      - ./ai-brain/capabilities:/app/capabilities
      - ./ai-brain/engines:/app/engines
      
      # Shared libraries
      - ./shared:/app/shared
      
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    
    restart: unless-stopped

  # Production Load Balancer with SSL
  nginx-production:
    build:
      context: ./nginx
      dockerfile: Dockerfile.production
    container_name: opsconductor-nginx-prod
    ports:
      - "80:80"
      - "443:443"
      - "8443:8443"  # Additional HTTPS port
    volumes:
      - ./nginx/production/nginx.production.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - ./production/logs/nginx:/var/log/nginx
    depends_on:
      ai-brain-production:
        condition: service_healthy
    networks:
      - opsconductor-prod-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  opsconductor-prod-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_prod_data:
  redis_prod_data:
  chromadb_prod_data:
  ollama_prod_models: