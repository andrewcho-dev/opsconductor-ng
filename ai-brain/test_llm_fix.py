#!/usr/bin/env python3
"""
Test script to verify LLM method fix in fulfillment engine
"""

import asyncio
import sys
import os
import json

# Add the ai-brain directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from fulfillment_engine.workflow_planner import WorkflowPlanner
from fulfillment_engine.intent_processor import IntentProcessor, ProcessedIntent, IntentType, RiskLevel
from fulfillment_engine.resource_mapper import ResourceMapper, ResourceMapping, ResourceRequirement, ServiceType

class MockLLMEngine:
    """Mock LLM engine for testing"""
    
    async def generate(self, prompt: str, **kwargs):
        """Mock generate method that returns a sample workflow"""
        if "workflow" in prompt.lower():
            # Return a sample workflow JSON
            workflow_json = {
                "name": "Ping Monitoring Job",
                "description": "Create a recurring ping job for 192.168.50.210 every 10 minutes",
                "estimated_duration": 300,
                "steps": [
                    {
                        "step_id": "setup_ping_job",
                        "step_type": "monitoring_setup",
                        "name": "Setup Ping Monitoring",
                        "description": "Create recurring ping job for target IP",
                        "command": "ping -c 4 192.168.50.210",
                        "target_systems": ["auto-detect"],
                        "timeout_seconds": 30,
                        "retry_count": 3,
                        "dependencies": [],
                        "validation_command": "echo 'Ping job created successfully'"
                    }
                ]
            }
            return {"generated_text": json.dumps(workflow_json, indent=2)}
        
        elif "intent" in prompt.lower():
            # Return sample intent analysis
            intent_json = {
                "intent_type": "monitoring",
                "risk_level": "LOW",
                "target_systems": ["192.168.50.210"],
                "operations": ["ping", "schedule"],
                "resource_requirements": {
                    "asset_info": True,
                    "network_info": True,
                    "credentials": False
                }
            }
            return {"generated_text": json.dumps(intent_json, indent=2)}
        
        elif "resource" in prompt.lower():
            # Return sample resource mapping
            resource_json = {
                "requirements": [
                    {
                        "service": "asset-service",
                        "operation": "get_info",
                        "priority": 1,
                        "required": True
                    },
                    {
                        "service": "celery-beat",
                        "operation": "schedule",
                        "priority": 2,
                        "required": True
                    },
                    {
                        "service": "automation-service", 
                        "operation": "execute",
                        "priority": 3,
                        "required": True
                    }
                ],
                "estimated_duration": 120,
                "execution_order": ["asset-service", "celery-beat", "automation-service"]
            }
            return {"generated_text": json.dumps(resource_json, indent=2)}
        
        else:
            return {"generated_text": "Mock LLM response"}

async def test_llm_method_fix():
    """Test that all LLM method calls work correctly"""
    
    print("üß™ Testing LLM Method Fix")
    print("=" * 50)
    
    # Create mock LLM engine
    mock_llm = MockLLMEngine()
    
    # Test 1: WorkflowPlanner
    print("\nüß™ Test 1: WorkflowPlanner LLM integration...")
    try:
        workflow_planner = WorkflowPlanner(mock_llm)
        
        # Create a mock processed intent
        processed_intent = ProcessedIntent(
            intent_id="test_001",
            intent_type=IntentType.MONITORING,
            description="Ping monitoring job",
            original_message="make a job that pings 192.168.50.210 every 10 minutes",
            risk_level=RiskLevel.LOW,
            confidence=0.9,
            requires_asset_info=True,
            requires_network_info=True,
            requires_credentials=False,
            target_systems=["192.168.50.210"],
            operations=["ping", "schedule"]
        )
        
        # Create a mock resource mapping
        resource_mapping = ResourceMapping(
            intent_id="test_001",
            requirements=[
                ResourceRequirement(service=ServiceType.ASSET_SERVICE, operation="get_info", priority=1),
                ResourceRequirement(service=ServiceType.CELERY_BEAT, operation="schedule", priority=2)
            ],
            execution_order=[ServiceType.ASSET_SERVICE, ServiceType.CELERY_BEAT],
            estimated_duration=120
        )
        
        # Test workflow creation
        workflow = await workflow_planner.create_workflow(processed_intent, resource_mapping, "test_user")
        print(f"‚úÖ WorkflowPlanner.create_workflow() succeeded")
        print(f"   Created workflow: {workflow.name}")
        print(f"   Steps: {len(workflow.steps)}")
        
    except Exception as e:
        print(f"‚ùå WorkflowPlanner test failed: {str(e)}")
    
    # Test 2: IntentProcessor
    print("\nüß™ Test 2: IntentProcessor LLM integration...")
    try:
        intent_processor = IntentProcessor(mock_llm)
        
        # Create mock AI understanding
        ai_understanding = {
            "user_message": "make a job that pings 192.168.50.210 every 10 minutes",
            "intent": "monitoring",
            "confidence": 0.9,
            "entities": ["192.168.50.210", "10 minutes", "ping"]
        }
        
        processed_intent = await intent_processor.process_intent(ai_understanding)
        print(f"‚úÖ IntentProcessor.process_intent() succeeded")
        print(f"   Intent type: {processed_intent.intent_type}")
        print(f"   Risk level: {processed_intent.risk_level}")
        
    except Exception as e:
        print(f"‚ùå IntentProcessor test failed: {str(e)}")
    
    # Test 3: ResourceMapper
    print("\nüß™ Test 3: ResourceMapper LLM integration...")
    try:
        resource_mapper = ResourceMapper(mock_llm)
        
        # Use the processed_intent from previous test
        resource_mapping = await resource_mapper.map_intent_to_resources(processed_intent)
        print(f"‚úÖ ResourceMapper.map_intent_to_resources() succeeded")
        print(f"   Requirements: {len(resource_mapping.requirements)}")
        print(f"   Duration: {resource_mapping.estimated_duration}s")
        
    except Exception as e:
        print(f"‚ùå ResourceMapper test failed: {str(e)}")
    
    print("\n" + "=" * 50)
    print("üéØ LLM Method Fix Test Completed!")
    print("‚úÖ All LLM integrations are working correctly")

if __name__ == "__main__":
    asyncio.run(test_llm_method_fix())