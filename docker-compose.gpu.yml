# Docker Compose GPU Override
# Use this file to ensure proper GPU access for AI services
# Usage: docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up

version: '3.8'

services:
  # NLP Service with GPU support
  nlp-service:
    environment:
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia

  # Vector Service with GPU support  
  vector-service:
    environment:
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia

  # LLM Service with GPU support
  llm-service:
    environment:
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia

  # Ollama with GPU support
  ollama:
    environment:
      - CUDA_VISIBLE_DEVICES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    runtime: nvidia